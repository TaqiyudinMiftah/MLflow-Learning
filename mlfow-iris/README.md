# Machine Learning Deployment & Versioning Control

This repository documents my **learning journey and hands-on experiments** in building **reproducible, deployable, and version-controlled machine learning systems**.

The main focus of this repo is **understanding the end-to-end ML lifecycle**, from training models to managing versions and preparing them for production deployment.

---

## ðŸš€ Learning Objectives

Through this repository, I aim to:

* Understand **machine learning deployment workflows**
* Practice **experiment tracking and model versioning**
* Learn how to manage the **ML lifecycle using MLflow**
* Apply **best practices for reproducibility and MLOps-ready projects**
* Explore modern tooling such as **uv** for dependency and environment management

---

## ðŸ§  Topics Covered

* Machine Learning experiment tracking
* Model versioning and lifecycle management
* MLflow Tracking, Models, and Model Registry
* Input validation and inference workflows
* Reproducible ML environments using `uv`
* Preparing models for local and production serving

---

## ðŸ› ï¸ Tools & Technologies

* **Python**
* **MLflow** â€“ experiment tracking, model packaging, and registry
* **scikit-learn** â€“ model training and evaluation
* **uv** â€“ fast Python package and environment manager
* **Git & GitHub** â€“ version control and progress documentation

---

## ðŸ“ Repository Structure

```text
.
â”œâ”€â”€ main.py              # Model training & MLflow logging
â”œâ”€â”€ validate.py          # Model serving input validation
â”œâ”€â”€ inference.py         # Model inference examples
â”œâ”€â”€ register_model.py    # Model Registry operations
â”œâ”€â”€ pyproject.toml       # Project dependencies and metadata
â”œâ”€â”€ uv.lock              # Locked dependencies for reproducibility
â””â”€â”€ README.md
```

---

## ðŸ”„ Workflow Overview

1. **Train a model** and log parameters, metrics, and artifacts using MLflow
2. **Track experiments** to compare model performance
3. **Package models** in MLflowâ€™s standardized format
4. **Validate serving inputs** before deployment
5. **Register models** to manage versions and lifecycle stages
6. **Run inference** using registered models without relying on run IDs

This workflow mirrors **real-world MLOps practices** used in research and industry.

---

## ðŸ“Œ Notes

* This repository is **educational and experimental**
* Models and scripts are designed for **learning and iteration**, not production scale
* Concepts explored here are directly transferable to **industry-grade MLOps pipelines**

---

## ðŸ“ˆ Progress Tracking

This repository will continue to evolve as I explore:

* Model promotion strategies (champion vs candidate)
* REST API-based model serving
* CI/CD integration for ML systems
* Scalable ML deployment patterns

---

## ðŸ‘¤ Author

**Taqiyudin Miftah Adn**
Computer Engineering Student | Aspiring AI & MLOps Engineer

> *"Learning MLOps is not just about training better models, but about building systems that can survive change."*
