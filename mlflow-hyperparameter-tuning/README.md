# MLflow Hyperparameter Tuning

Folder ini berisi pembelajaran tentang hyperparameter tuning dengan MLflow, mencakup berbagai metode dan best practices.

## ğŸ“š Materi yang Dipelajari

### 1. Basic Concepts
- **Parent-Child Runs**: Cara mengorganisir multiple experiments
- **Nested Runs**: Tracking hyperparameter tuning experiments
- **Run Comparison**: Membandingkan hasil dari berbagai hyperparameter

### 2. Metode Hyperparameter Tuning

#### Grid Search (`grid_search.py`)
- Exhaustive search pada semua kombinasi parameter
- Menggunakan nested runs untuk tracking
- Visualisasi hasil tuning

#### Random Search (`random_search.py`)
- Random sampling dari parameter space
- Lebih efisien untuk large parameter spaces
- Probability distributions untuk sampling

#### Bayesian Optimization (`optuna_tuning.py`)
- Menggunakan Optuna untuk intelligent search
- MLflow callback untuk automatic logging
- Visualization dengan Optuna plots

### 3. Advanced Features

#### Autologging (`autologging_demo.py`)
- Automatic parameter & metrics logging
- Framework-specific autologging
- Custom logging vs autologging

#### Comparison & Analysis (`compare_runs.py`)
- Search & filter runs berdasarkan metrics
- Parallel coordinates plot
- Best model selection

## ğŸš€ Quick Start

### Install Dependencies
```bash
pip install mlflow scikit-learn optuna pandas numpy matplotlib seaborn
```

### Jalankan Experiments

1. **Grid Search**:
```bash
python grid_search.py
```

2. **Random Search**:
```bash
python random_search.py
```

3. **Bayesian Optimization dengan Optuna**:
```bash
python optuna_tuning.py
```

4. **Autologging Demo**:
```bash
python autologging_demo.py
```

5. **Compare & Analyze Results**:
```bash
python compare_runs.py
```

## ğŸ“Š MLflow UI

Lihat hasil experiments:
```bash
mlflow ui --backend-store-uri file:./mlruns
```

Buka browser: http://localhost:5000

## ğŸ¯ Learning Path

1. âœ… Mulai dengan `grid_search.py` - Pahami konsep parent-child runs
2. âœ… Lanjut ke `random_search.py` - Lebih efisien dari grid search
3. âœ… Coba `optuna_tuning.py` - Bayesian optimization yang powerful
4. âœ… Eksplorasi `autologging_demo.py` - Simplify logging process
5. âœ… Analisis dengan `compare_runs.py` - Find best hyperparameters

## ğŸ“ Key Concepts

### Parent-Child Runs Structure
```
Parent Run (Hyperparameter Tuning)
â”œâ”€â”€ Child Run 1 (params: n_estimators=50, max_depth=5)
â”œâ”€â”€ Child Run 2 (params: n_estimators=100, max_depth=10)
â””â”€â”€ Child Run 3 (params: n_estimators=200, max_depth=15)
```

### Best Practices
- âœ… Gunakan parent run untuk grup related experiments
- âœ… Log semua hyperparameters sebagai params
- âœ… Log evaluation metrics untuk comparison
- âœ… Simpan best model dengan signature
- âœ… Tag runs dengan metadata yang meaningful
- âœ… Gunakan experiment naming yang konsisten

## ğŸ” What's Next?

Setelah menguasai hyperparameter tuning:
- **MLflow Projects**: Reproducible ML workflows
- **Custom Models**: mlflow.pyfunc untuk custom inference logic
- **Model Evaluation**: mlflow.evaluate() untuk comprehensive assessment
- **Production Deployment**: Docker, Kubernetes, cloud platforms

## ğŸ“š Resources

- [MLflow Tracking Documentation](https://mlflow.org/docs/latest/tracking.html)
- [MLflow Python API](https://mlflow.org/docs/latest/python_api/index.html)
- [Optuna Integration](https://optuna.readthedocs.io/)
